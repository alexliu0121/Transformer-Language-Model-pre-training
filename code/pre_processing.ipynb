{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39e854b8-e238-4fd1-a594-a83c73737f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Downloading accelerate-0.27.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from accelerate) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from accelerate) (2.1.2+cu121)\n",
      "Collecting huggingface-hub (from accelerate)\n",
      "  Using cached huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting safetensors>=0.3.1 (from accelerate)\n",
      "  Using cached safetensors-0.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.0)\n",
      "Requirement already satisfied: jinja2 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (2023.4.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Collecting fsspec (from torch>=1.10.0->accelerate)\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: requests in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading accelerate-0.27.0-py3-none-any.whl (279 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.7/279.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached safetensors-0.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Using cached huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, fsspec, huggingface-hub, accelerate\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "Successfully installed accelerate-0.27.0 fsspec-2024.2.0 huggingface-hub-0.20.3 safetensors-0.4.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bc127a4-581a-4734-91f3-fdbbc2b7152a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers[torch]\n",
      "  Using cached transformers-4.37.2-py3-none-any.whl.metadata (129 kB)\n",
      "Requirement already satisfied: filelock in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from transformers[torch]) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from transformers[torch]) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from transformers[torch]) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from transformers[torch]) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers[torch])\n",
      "  Using cached regex-2023.12.25-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from transformers[torch]) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers[torch])\n",
      "  Using cached tokenizers-0.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from transformers[torch]) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from transformers[torch]) (4.66.1)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.11 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from transformers[torch]) (2.1.2+cu121)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from transformers[torch]) (0.27.0)\n",
      "Requirement already satisfied: psutil in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (3.0)\n",
      "Requirement already satisfied: jinja2 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (3.1.3)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from torch!=1.12.0,>=1.11->transformers[torch]) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from requests->transformers[torch]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from requests->transformers[torch]) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from requests->transformers[torch]) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from jinja2->torch!=1.12.0,>=1.11->transformers[torch]) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/snoronha/projects/244/env/lib/python3.9/site-packages (from sympy->torch!=1.12.0,>=1.11->transformers[torch]) (1.3.0)\n",
      "Using cached regex-2023.12.25-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "Using cached tokenizers-0.15.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Using cached transformers-4.37.2-py3-none-any.whl (8.4 MB)\n",
      "Installing collected packages: regex, tokenizers, transformers\n",
      "Successfully installed regex-2023.12.25 tokenizers-0.15.1 transformers-4.37.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "375987a3-e6e9-40ba-8380-1fcb11ce57d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f6ffa68-3c25-4178-85ec-18cc28daf07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = load_dataset(\"wikitext\",\"wikitext-2-raw-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8131b6a9-51ff-414b-ac21-3dd3f51fe9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 4358\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 36718\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 3760\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cd4a728-a7cc-4312-8466-5ed109516771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 36718\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb81e1d9-8747-4e60-8f5f-2abf12edf6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6041db78-4b93-4bec-b3ef-ef8fc3558760",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilgpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da297a28-137b-432b-bd23-60c8df7d4969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='distilgpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3e7ac9d-6784-484b-a918-e777bf623d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' = = Development = = \\n'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki['train'][19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d321c8f-9176-4f15-baec-2e4995c4b70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 4358\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 36718\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 3760\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e44ef12-4c55-4815-b831-e9e2d024a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '6,7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebf50a3e-9582-4381-9f91-953e4545c54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' = = Development = = \\n', '']\n"
     ]
    }
   ],
   "source": [
    "print(wiki['train']['text'][19:21])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5217d9a0-12b5-43f3-8b6c-1e5adc1f4099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer([\" \".join(x) for x in examples['text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37d125a8-49d2-4c98-a12f-b3b792c61ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_wiki = wiki.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc= 4,\n",
    "    remove_columns=wiki['train'].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cc8574a-1606-46b7-b371-ba3884601a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[220, 796, 220, 220, 796, 220, 220, 360, 304, 410, 304, 300, 267, 279, 285, 304, 299, 256, 220, 220, 796, 220, 220, 796, 220, 220, 220, 198]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "test_val = 19\n",
    "print(tokenized_wiki['train']['input_ids'][test_val])\n",
    "print(tokenized_wiki['train']['attention_mask'][test_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12843066-247e-4dff-b8b7-08527211d58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed496a39-149c-4587-9b2e-b88651e9f088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    \n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "\n",
    "    if total_length >= block_size:\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "    \n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62c057b9-44dc-43b0-937c-d95fc2010914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e86cef5da44b58b7d688ca643d29d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/4358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f0c09218bb94d798c68f1b6a6102815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/36718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b551837bb84d5d9046fac8e97047f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/3760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm_dataset = tokenized_wiki.map(group_texts, batched=True, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "039d159a-b281-489b-99f9-7da3695a77b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7fd0b264d3a0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/snoronha/projects/244/assignment2/env/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed7cbf45-1e3b-4ea7-8dee-7dd6be10c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c36fe311-9e9c-4c56-a7a4-5499713daf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af6193c5-725a-4c32-aabd-c00b717230c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorForLanguageModeling(tokenizer=GPT2TokenizerFast(name_or_path='distilgpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True), mlm=False, mlm_probability=0.15, pad_to_multiple_of=None, tf_experimental_compile=False, return_tensors='pt')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8b2d46c-0277-4509-ae68-018cc403a13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c79a9ac-bfd7-49e1-b008-bd9f6f8806a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdistilgpt2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/244/assignment2/env/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:469\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    466\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    468\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mauto_map\n\u001b[0;32m--> 469\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_mapping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m resolve_trust_remote_code(\n\u001b[1;32m    471\u001b[0m     trust_remote_code, pretrained_model_name_or_path, has_local_code, has_remote_code\n\u001b[1;32m    472\u001b[0m )\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_remote_code \u001b[38;5;129;01mand\u001b[39;00m trust_remote_code:\n",
      "File \u001b[0;32m~/projects/244/assignment2/env/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:674\u001b[0m, in \u001b[0;36m_LazyAutoMapping.keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkeys\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 674\u001b[0m     mapping_keys \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    675\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_attr_from_module(key, name)\n\u001b[1;32m    676\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config_mapping\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    677\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m    678\u001b[0m     ]\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping_keys \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extra_content\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32m~/projects/244/assignment2/env/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:675\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkeys\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     mapping_keys \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 675\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_attr_from_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    676\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key, name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config_mapping\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    677\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m    678\u001b[0m     ]\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping_keys \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extra_content\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32m~/projects/244/assignment2/env/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:671\u001b[0m, in \u001b[0;36m_LazyAutoMapping._load_attr_from_module\u001b[0;34m(self, model_type, attr)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules[module_name] \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers.models\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 671\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetattribute_from_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_modules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/244/assignment2/env/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:616\u001b[0m, in \u001b[0;36mgetattribute_from_module\u001b[0;34m(module, attr)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(attr, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(getattribute_from_module(module, a) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m attr)\n\u001b[0;32m--> 616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, attr)\n\u001b[1;32m    618\u001b[0m \u001b[38;5;66;03m# Some of the mappings have entries model_type -> object of another model type. In that case we try to grab the\u001b[39;00m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# object at the top level.\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/244/assignment2/env/lib/python3.9/site-packages/transformers/utils/import_utils.py:1076\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1076\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1077\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/projects/244/assignment2/env/lib/python3.9/site-packages/transformers/utils/import_utils.py:1086\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1086\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1087\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1088\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1089\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1090\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1091\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/projects/244/assignment2/env/lib/python3.9/site-packages/transformers/models/gpt_neo/configuration_gpt_neo.py:26\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OnnxConfigWithPast\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[0;32m---> 26\u001b[0m logger \u001b[38;5;241m=\u001b[39m \u001b[43mlogging\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_logger\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m GPT_NEO_PRETRAINED_CONFIG_ARCHIVE_MAP \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEleutherAI/gpt-neo-1.3B\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/EleutherAI/gpt-neo-1.3B/resolve/main/config.json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# See all GPTNeo models at https://huggingface.co/models?filter=gpt_neo\u001b[39;00m\n\u001b[1;32m     31\u001b[0m }\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGPTNeoConfig\u001b[39;00m(PretrainedConfig):\n",
      "File \u001b[0;32m~/projects/244/assignment2/env/lib/python3.9/site-packages/transformers/utils/logging.py:125\u001b[0m, in \u001b[0;36mget_logger\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    122\u001b[0m     name \u001b[38;5;241m=\u001b[39m _get_library_name()\n\u001b[1;32m    124\u001b[0m _configure_library_root_logger()\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlogging\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetLogger\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/logging/__init__.py:2042\u001b[0m, in \u001b[0;36mgetLogger\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m   2040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;241m==\u001b[39m root\u001b[38;5;241m.\u001b[39mname:\n\u001b[1;32m   2041\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m root\n\u001b[0;32m-> 2042\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetLogger\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/logging/__init__.py:1298\u001b[0m, in \u001b[0;36mManager.getLogger\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA logger name must be a string\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1298\u001b[0m \u001b[43m_acquireLock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1300\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloggerDict:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/logging/__init__.py:225\u001b[0m, in \u001b[0;36m_acquireLock\u001b[0;34m()\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;124;03mAcquire the module-level lock for serializing access to shared data.\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \n\u001b[1;32m    222\u001b[0m \u001b[38;5;124;03mThis should be released with _releaseLock().\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _lock:\n\u001b[0;32m--> 225\u001b[0m     \u001b[43m_lock\u001b[49m\u001b[38;5;241m.\u001b[39macquire()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ce7957-f911-4af9-98cb-d84d2c5bec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='training_dir',\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f80e02d-e7cf-4e53-81bd-98f0dd869fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_dataset[\"train\"],\n",
    "    eval_dataset=lm_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4298089-6d95-4fc2-bf9d-f3af8ff0ecac",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['NCCL_SHM_DISABLE']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19b71a32-56c7-414c-85c5-1943b9081d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 22.72\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\") # perplexity without training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94bac802-148a-4dc2-aa9c-a44415d2d135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snoronha/projects/244/assignment2/env/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='38013' max='38013' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [38013/38013 34:04, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.353400</td>\n",
       "      <td>1.288102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.279200</td>\n",
       "      <td>1.232189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.253800</td>\n",
       "      <td>1.219000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=38013, training_loss=1.3539684697465464, metrics={'train_runtime': 2044.3574, 'train_samples_per_second': 148.747, 'train_steps_per_second': 18.594, 'total_flos': 9932281435127808.0, 'train_loss': 1.3539684697465464, 'epoch': 3.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fb97347-e691-432c-bddf-f627c06068ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1494' max='1494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1494/1494 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 3.38\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4bcd86fd-ce92-4480-8c17-f596994975df",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Whats language without the inherent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0971966e-e477-4844-a016-9a5ab540dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c8d605e5-8aa4-4c3e-a924-d65ee0c171f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "da1e1486-6fc6-49c5-ae88-d9446cdde815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Whats language without the inherent y   e x p e r i e n c e   i n   a   v e r y   o f   W e n d s   s i n c e'}]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863e967a-c32f-48c2-a51a-034ed2e4b145",
   "metadata": {},
   "source": [
    "# Finetune this model for relational tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbc14617-b616-4048-8a4f-aabeb2f5dbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56b88894-74d6-47e2-ac48-79db36f97657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.softmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00984707-64cb-49b5-9d11-cca70cf080c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## using last assignment tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16203ca7-7943-4e87-9050-6aa4741343bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext in ./env/lib/python3.9/site-packages (0.17.0)\n",
      "Requirement already satisfied: tqdm in ./env/lib/python3.9/site-packages (from torchtext) (4.66.2)\n",
      "Requirement already satisfied: requests in ./env/lib/python3.9/site-packages (from torchtext) (2.31.0)\n",
      "Requirement already satisfied: torch==2.2.0 in ./env/lib/python3.9/site-packages (from torchtext) (2.2.0)\n",
      "Requirement already satisfied: numpy in ./env/lib/python3.9/site-packages (from torchtext) (1.26.4)\n",
      "Requirement already satisfied: torchdata==0.7.1 in ./env/lib/python3.9/site-packages (from torchtext) (0.7.1)\n",
      "Requirement already satisfied: filelock in ./env/lib/python3.9/site-packages (from torch==2.2.0->torchtext) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./env/lib/python3.9/site-packages (from torch==2.2.0->torchtext) (4.9.0)\n",
      "Requirement already satisfied: sympy in ./env/lib/python3.9/site-packages (from torch==2.2.0->torchtext) (1.12)\n",
      "Requirement already satisfied: networkx in ./env/lib/python3.9/site-packages (from torch==2.2.0->torchtext) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./env/lib/python3.9/site-packages (from torch==2.2.0->torchtext) (3.1.3)\n",
      "Requirement already satisfied: fsspec in ./env/lib/python3.9/site-packages (from torch==2.2.0->torchtext) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./env/lib/python3.9/site-packages (from torch==2.2.0->torchtext) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./env/lib/python3.9/site-packages (from torch==2.2.0->torchtext) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./env/lib/python3.9/site-packages (from torch==2.2.0->torchtext) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./env/lib/python3.9/site-packages (from torch==2.2.0->torchtext) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./env/lib/python3.9/site-packages (from torch==2.2.0->torchtext) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./env/lib/python3.9/site-packages (from torch==2.2.0->torchtext) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./env/lib/python3.9/site-packages (from torch==2.2.0->torchtext) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./env/lib/python3.9/site-packages (from torch==2.2.0->torchtext) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./env/lib/python3.9/site-packages (from torch==2.2.0->torchtext) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in ./env/lib/python3.9/site-packages (from torch==2.2.0->torchtext) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./env/lib/python3.9/site-packages (from torch==2.2.0->torchtext) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in ./env/lib/python3.9/site-packages (from torch==2.2.0->torchtext) (2.2.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in ./env/lib/python3.9/site-packages (from torchdata==0.7.1->torchtext) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./env/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->torchtext) (12.3.101)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.9/site-packages (from requests->torchtext) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.9/site-packages (from requests->torchtext) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.9/site-packages (from requests->torchtext) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./env/lib/python3.9/site-packages (from jinja2->torch==2.2.0->torchtext) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./env/lib/python3.9/site-packages (from sympy->torch==2.2.0->torchtext) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e495a9c8-a950-40dc-8a7f-a7ad37623cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import torchtext\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from collections import Counter, OrderedDict\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.vocab import vocab\n",
    "from torch import nn\n",
    "from tqdm import tqdm \n",
    "import datasets\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "49ecb5e6-7a02-4adb-b25a-a204af63df3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "83176d70-c263-4133-b4f0-360980e57c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "871008d3-b0de-4444-a0bf-7da74f1704c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "22e36a9c-9429-4d25-9d6e-b3784d60b782",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hw1_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e28f7d3b-b4a7-442a-a9fa-f39b04841158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterances</th>\n",
       "      <th>IOB Slot tags</th>\n",
       "      <th>Core Relations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>who plays luke on star wars new hope</td>\n",
       "      <td>O O B_char O B_movie I_movie I_movie I_movie</td>\n",
       "      <td>movie.starring.actor movie.starring.character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>show credits for the godfather</td>\n",
       "      <td>O O O B_movie I_movie</td>\n",
       "      <td>movie.starring.actor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>who was the main actor in the exorcist</td>\n",
       "      <td>O O O O O O B_movie I_movie</td>\n",
       "      <td>movie.starring.actor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who played dory on finding nemo</td>\n",
       "      <td>O O B_char O B_movie I_movie</td>\n",
       "      <td>movie.starring.actor movie.starring.character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who was the female lead in resident evil</td>\n",
       "      <td>O O O O O O B_movie I_movie</td>\n",
       "      <td>movie.starring.actor actor.gender</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 utterances  \\\n",
       "0      who plays luke on star wars new hope   \n",
       "1            show credits for the godfather   \n",
       "2    who was the main actor in the exorcist   \n",
       "3           who played dory on finding nemo   \n",
       "4  who was the female lead in resident evil   \n",
       "\n",
       "                                  IOB Slot tags  \\\n",
       "0  O O B_char O B_movie I_movie I_movie I_movie   \n",
       "1                         O O O B_movie I_movie   \n",
       "2                   O O O O O O B_movie I_movie   \n",
       "3                  O O B_char O B_movie I_movie   \n",
       "4                   O O O O O O B_movie I_movie   \n",
       "\n",
       "                                  Core Relations  \n",
       "0  movie.starring.actor movie.starring.character  \n",
       "1                           movie.starring.actor  \n",
       "2                           movie.starring.actor  \n",
       "3  movie.starring.actor movie.starring.character  \n",
       "4              movie.starring.actor actor.gender  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f15855-6343-448f-8942-2671ac90d27b",
   "metadata": {},
   "source": [
    "### creating the vocab for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6f3bf5b8-1c5b-4d26-8776-9708e2d09b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(set([val for row in df['utterances'].to_list() for val in row.split(' ')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "23dbc6d5-78ca-439e-a8a8-3cd1a4306475",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_freq_tuples = sorted(counter.items(), key=lambda x: x[1], reverse=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c9a65cab-d443-42c8-b9a6-1620ebd49367",
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_token = '<unk>'\n",
    "default_index = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "02816e13-5dcf-4f9c-805e-f16801fc47c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = list(set([val for row in df['utterances'].to_list() for val in row.split(' ')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "34f6390b-d300-4c61-a080-4438201596f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lion',\n",
       " 'berry',\n",
       " 'should',\n",
       " 'charles',\n",
       " 'friday',\n",
       " 'la',\n",
       " 'informaion',\n",
       " 'warner',\n",
       " 'starting',\n",
       " 'rudy']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6189c089-003c-4e02-8d39-e3a949471364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterances</th>\n",
       "      <th>IOB Slot tags</th>\n",
       "      <th>Core Relations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>who plays luke on star wars new hope</td>\n",
       "      <td>O O B_char O B_movie I_movie I_movie I_movie</td>\n",
       "      <td>movie.starring.actor movie.starring.character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>show credits for the godfather</td>\n",
       "      <td>O O O B_movie I_movie</td>\n",
       "      <td>movie.starring.actor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>who was the main actor in the exorcist</td>\n",
       "      <td>O O O O O O B_movie I_movie</td>\n",
       "      <td>movie.starring.actor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who played dory on finding nemo</td>\n",
       "      <td>O O B_char O B_movie I_movie</td>\n",
       "      <td>movie.starring.actor movie.starring.character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who was the female lead in resident evil</td>\n",
       "      <td>O O O O O O B_movie I_movie</td>\n",
       "      <td>movie.starring.actor actor.gender</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 utterances  \\\n",
       "0      who plays luke on star wars new hope   \n",
       "1            show credits for the godfather   \n",
       "2    who was the main actor in the exorcist   \n",
       "3           who played dory on finding nemo   \n",
       "4  who was the female lead in resident evil   \n",
       "\n",
       "                                  IOB Slot tags  \\\n",
       "0  O O B_char O B_movie I_movie I_movie I_movie   \n",
       "1                         O O O B_movie I_movie   \n",
       "2                   O O O O O O B_movie I_movie   \n",
       "3                  O O B_char O B_movie I_movie   \n",
       "4                   O O O O O O B_movie I_movie   \n",
       "\n",
       "                                  Core Relations  \n",
       "0  movie.starring.actor movie.starring.character  \n",
       "1                           movie.starring.actor  \n",
       "2                           movie.starring.actor  \n",
       "3  movie.starring.actor movie.starring.character  \n",
       "4              movie.starring.actor actor.gender  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7dcf8678-b384-45e8-b941-8cfa1ecbc9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13305/4241390190.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Core Relations'].fillna('None', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df['Core Relations'].fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "8414b3f3-f955-4bc6-b0a9-99ce7d085226",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_rels_list = sorted(list(set([j for i in df[\"Core Relations\"].to_list() for j in str(i).split(\" \")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7b7ca0d4-311f-4f03-8128-215e7ed45511",
   "metadata": {},
   "outputs": [],
   "source": [
    "core_rels_to_index_dict = {val: index for index, val in enumerate(sorted(core_rels_list))}\n",
    "index_to_core_rels_dict = {index: val for val, index in core_rels_to_index_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "55f8a965-d03f-470e-8c7d-1de5d9909edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(text, token_to_index):\n",
    "    one_hot_vector = [0 for i in range(len(token_to_index))]\n",
    "\n",
    "    for token in str(text) if isinstance(text, float) else text.split(' '):\n",
    "        one_hot_vector[token_to_index[token]] = 1\n",
    "    return one_hot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d8dd401c-209d-40f4-9e61-d4d103d08900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize('movie.gross_revenue', core_rels_to_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8164d3e8-59a5-4272-828f-e284991da7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at training_dir/checkpoint-38000 were not used when initializing GPT2ForSequenceClassification: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at training_dir/checkpoint-38000 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "gpt2 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'training_dir/checkpoint-38000',\n",
    "    num_labels=len(core_rels_list),\n",
    "    problem_type=\"multi_label_classification\",  # this is important\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1fadadb0-e1b3-4233-97a9-88d45c69468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['core_rel_vectorized'] = df['Core Relations'].apply(lambda x: vectorize(x, core_rels_to_index_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "278c3bd3-d7f3-4eba-8c36-c91f466a631f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterances</th>\n",
       "      <th>IOB Slot tags</th>\n",
       "      <th>Core Relations</th>\n",
       "      <th>core_rel_vectorized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>who plays luke on star wars new hope</td>\n",
       "      <td>O O B_char O B_movie I_movie I_movie I_movie</td>\n",
       "      <td>movie.starring.actor movie.starring.character</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>show credits for the godfather</td>\n",
       "      <td>O O O B_movie I_movie</td>\n",
       "      <td>movie.starring.actor</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>who was the main actor in the exorcist</td>\n",
       "      <td>O O O O O O B_movie I_movie</td>\n",
       "      <td>movie.starring.actor</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who played dory on finding nemo</td>\n",
       "      <td>O O B_char O B_movie I_movie</td>\n",
       "      <td>movie.starring.actor movie.starring.character</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who was the female lead in resident evil</td>\n",
       "      <td>O O O O O O B_movie I_movie</td>\n",
       "      <td>movie.starring.actor actor.gender</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 utterances  \\\n",
       "0      who plays luke on star wars new hope   \n",
       "1            show credits for the godfather   \n",
       "2    who was the main actor in the exorcist   \n",
       "3           who played dory on finding nemo   \n",
       "4  who was the female lead in resident evil   \n",
       "\n",
       "                                  IOB Slot tags  \\\n",
       "0  O O B_char O B_movie I_movie I_movie I_movie   \n",
       "1                         O O O B_movie I_movie   \n",
       "2                   O O O O O O B_movie I_movie   \n",
       "3                  O O B_char O B_movie I_movie   \n",
       "4                   O O O O O O B_movie I_movie   \n",
       "\n",
       "                                  Core Relations  \\\n",
       "0  movie.starring.actor movie.starring.character   \n",
       "1                           movie.starring.actor   \n",
       "2                           movie.starring.actor   \n",
       "3  movie.starring.actor movie.starring.character   \n",
       "4              movie.starring.actor actor.gender   \n",
       "\n",
       "                                 core_rel_vectorized  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b5aceab2-7de1-4c03-bc91-13db894cfe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_encode(examples):\n",
    "    return tokenizer(examples[\"utterances\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e801931c-4fe3-4600-a0ae-80a7a6880266",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['IOB Slot tags', 'Core Relations'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ed1ab83b-7b09-4f6d-8bd1-fdf7d4c4dbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\n",
    "    'core_rel_vectorized':'labels'\n",
    "},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4b9aecdf-a0a8-48d3-a912-19627fa26e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterances</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>who plays luke on star wars new hope</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>show credits for the godfather</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>who was the main actor in the exorcist</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who played dory on finding nemo</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who was the female lead in resident evil</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248</th>\n",
       "      <td>revenue for titanic</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2249</th>\n",
       "      <td>total titanic revenues</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>what was the revenue for toy story 3</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2251</th>\n",
       "      <td>dark knight revenue</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2252</th>\n",
       "      <td>how much did the dark night generate</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2253 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    utterances  \\\n",
       "0         who plays luke on star wars new hope   \n",
       "1               show credits for the godfather   \n",
       "2       who was the main actor in the exorcist   \n",
       "3              who played dory on finding nemo   \n",
       "4     who was the female lead in resident evil   \n",
       "...                                        ...   \n",
       "2248                       revenue for titanic   \n",
       "2249                    total titanic revenues   \n",
       "2250      what was the revenue for toy story 3   \n",
       "2251                       dark knight revenue   \n",
       "2252      how much did the dark night generate   \n",
       "\n",
       "                                                 labels  \n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4     [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                 ...  \n",
       "2248  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2249  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2250  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2251  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2252  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[2253 rows x 2 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "74e5564c-39a0-4c65-864b-d4cf83765638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>utterances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>star of thor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>who is in the movie the campaign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>list the cast of the movie the campaign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>who was in twilight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>who is in vulguria</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                               utterances\n",
       "0   1                             star of thor\n",
       "1   2         who is in the movie the campaign\n",
       "2   3  list the cast of the movie the campaign\n",
       "3   4                      who was in twilight\n",
       "4   5                       who is in vulguria"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('hw2_test.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "250683f6-5d5c-477a-aef1-2fe71ee45b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[['utterances']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "05d9a7a9-4eae-496b-8992-9546b26e2347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>star of thor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>who is in the movie the campaign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>list the cast of the movie the campaign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who was in twilight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who is in vulguria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>trailer for star wars a new hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>show resident evil movies with trailers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>can i see previews for upcoming warner brother...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>how many woody allen movies are set in new yor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>how many scorsese films were filmed in france</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>981 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            utterances\n",
       "0                                         star of thor\n",
       "1                     who is in the movie the campaign\n",
       "2              list the cast of the movie the campaign\n",
       "3                                  who was in twilight\n",
       "4                                   who is in vulguria\n",
       "..                                                 ...\n",
       "976                   trailer for star wars a new hope\n",
       "977            show resident evil movies with trailers\n",
       "978  can i see previews for upcoming warner brother...\n",
       "979  how many woody allen movies are set in new yor...\n",
       "980      how many scorsese films were filmed in france\n",
       "\n",
       "[981 rows x 1 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc38a54c-2db6-4df7-a83d-25336bdb175f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0fa648c3-665e-4cf5-9c1d-8b3749fc9536",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_ds = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1365427f-609c-4b57-ace7-4848db7589ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(train_df)\n",
    "valid_ds = Dataset.from_pandas(valid_ds)\n",
    "test_ds = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f276bfae-3029-4faa-9e51-dba1e2fb69a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DatasetDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "96c7a285-0b85-4b8e-b208-5bdaf056b4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['train'] = train_ds\n",
    "ds['valid'] = valid_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2435aef8-0764-49d0-8f3f-f9d396204c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['utterances', 'labels', '__index_level_0__'],\n",
       "        num_rows: 1802\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['utterances', 'labels', '__index_level_0__'],\n",
       "        num_rows: 451\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "38849c4b-c22b-4cd4-86b7-ebe5551de4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['utterances', 'labels', '__index_level_0__'],\n",
       "        num_rows: 1802\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['utterances', 'labels', '__index_level_0__'],\n",
       "        num_rows: 451\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f99c0f02-0996-4ae0-9f9d-7d4d72b8f67b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97c8da00621a40ff9d6bb79eeaba231d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e092277ef84e84b862a4927fdc32c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/451 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cast label IDs to floats\n",
    "ds.set_format(\"torch\")\n",
    "ds = (ds\n",
    "          .map(lambda x : {\"float_labels\": x[\"labels\"].to(torch.float)}, remove_columns=[\"labels\"])\n",
    "          .rename_column(\"float_labels\", \"labels\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "94823ff1-4bdb-4045-aff2-70b82eb935fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['test'] = test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "748a30b3-57c5-4bde-be32-a82496ef9ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd100beb2ba245fda4ce7e75c63e63c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1802 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c0a8f55003c4a86ad53d17da553471e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/451 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60819a0764804acba8c28c3eb92cdeb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/981 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds  = ds.map(tokenize_and_encode, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "7132eeea-04da-44b2-b344-7ec5a8b75bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'utterances': 'when was in july released',\n",
       " '__index_level_0__': tensor(311),\n",
       " 'labels': tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.]),\n",
       " 'input_ids': tensor([12518,   373,   287,   474,  2062,  2716]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1])}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a1b9eda8-ff79-4883-8341-5a1f94dea55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2.config.pad_token_id = gpt2.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "43271bd8-0117-4f8e-84a2-402f57cb3d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions = p.predictions > 0.5  # Assuming threshold for classification is 0.5, adjust as needed\n",
    "    labels = p.label_ids\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='micro')\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "810b4e01-d343-41c0-b148-304fb0c84b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\"testtraining\", num_train_epochs=1)\n",
    "\n",
    "trainer = Trainer(model=gpt2, args=args, train_dataset=ds[\"train\"], eval_dataset=ds['valid'], tokenizer=tokenizer, compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ecc58550-15e9-44f4-8ee2-d1821487b0c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='226' max='226' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [226/226 00:50, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=226, training_loss=0.040479731770743314, metrics={'train_runtime': 50.6504, 'train_samples_per_second': 35.577, 'train_steps_per_second': 4.462, 'total_flos': 5299711441920.0, 'train_loss': 0.040479731770743314, 'epoch': 1.0})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "64362db3-7f8e-4c18-be71-dedbda6ee170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.05519789084792137,\n",
       " 'eval_accuracy': 0.7649667405764967,\n",
       " 'eval_precision': 0.9391727493917275,\n",
       " 'eval_recall': 0.7909836065573771,\n",
       " 'eval_f1': 0.8587319243604005,\n",
       " 'eval_runtime': 1.5561,\n",
       " 'eval_samples_per_second': 289.832,\n",
       " 'eval_steps_per_second': 36.631,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4f6722e2-f630-475f-83b4-7e773164315a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(ds['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d77a4446-b8e9-4064-9434-01fe164280bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "981"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe447dd2-48d9-4548-8d13-7a97f5341c6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredictions\u001b[49m\u001b[38;5;241m.\u001b[39mpredictions \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m  \u001b[38;5;66;03m# Assuming threshold for classification is 0.5, adjust as needed\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = predictions.predictions > 0.5  # Assuming threshold for classification is 0.5, adjust as needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7cd8b6-8205-4b3c-8ec0-f4870af23dea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment2",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
